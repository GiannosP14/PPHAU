{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55392d22",
   "metadata": {},
   "source": [
    "Imports & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c09c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import binary_dilation\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "\n",
    "NUM_SAMPLES = 10\n",
    "N_CLUSTERS = 2\n",
    "YOLO_WEIGHTS = \"yolov8n.pt\"\n",
    "\n",
    "EXTRACTED_RGB = \"data/rgb\"\n",
    "EXTRACTED_DEPTH = \"data/depth\"\n",
    "INTRINSICS_FILE = \"data/intrinsics.txt\"\n",
    "OVERLAY_OUT = \"results\"\n",
    "\n",
    "os.makedirs(OVERLAY_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde3b655",
   "metadata": {},
   "source": [
    "Load Camera Intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a59c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INTRINSICS_FILE, \"r\") as f:\n",
    "    fx, fy, cx, cy = map(float, f.readline().strip().split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3d90b",
   "metadata": {},
   "source": [
    "Depth -> XYZ Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531787bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_to_xyz(depth_img, fx, fy, cx, cy):\n",
    "    h, w = depth_img.shape\n",
    "    x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    Z = depth_img.astype(np.float32) / 1000.0\n",
    "    X = (x - cx) * Z / fx\n",
    "    Y = (y - cy) * Z / fy\n",
    "    return np.stack((X, Y, Z), axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8b8b5",
   "metadata": {},
   "source": [
    "KMeans Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2f8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_cluster(roi_rgb, roi_xyz, n_clusters=N_CLUSTERS):\n",
    "    h, w = roi_rgb.shape[:2]\n",
    "    rgb_flat = roi_rgb.reshape(-1, 3).astype(np.float32)\n",
    "    xyz_flat = roi_xyz.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "    valid = np.isfinite(xyz_flat).all(axis=1) & (xyz_flat[:, 2] > 0)\n",
    "    if valid.sum() < n_clusters:\n",
    "        return np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    features = np.concatenate([rgb_flat[valid], xyz_flat[valid]], axis=1)\n",
    "\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(features)\n",
    "\n",
    "    labels = np.full(rgb_flat.shape[0], -1, dtype=np.int32)\n",
    "    labels[valid] = kmeans.labels_\n",
    "    labels = labels.reshape(h, w)\n",
    "\n",
    "\n",
    "    cluster_means = [\n",
    "        xyz_flat[labels.reshape(-1) == k][:, 2].mean() if np.any(labels == k) else 1e9\n",
    "        for k in range(n_clusters)\n",
    "    ]\n",
    "    fg_cluster = np.argmin(cluster_means)\n",
    "\n",
    "    mask = (labels == fg_cluster).astype(np.uint8)\n",
    "    mask = binary_dilation(mask, iterations=2)\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844f4bd",
   "metadata": {},
   "source": [
    "Overlay Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d18ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_function(image, mask, alpha=0.5):\n",
    "    color_map = np.array([[0, 0, 0], [255, 255, 50]])\n",
    "    colored = color_map[mask]\n",
    "    return (image * alpha + colored * (1 - alpha)).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0fde2",
   "metadata": {},
   "source": [
    "Load YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc99191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(YOLO_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb37642",
   "metadata": {},
   "source": [
    "Segmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e04807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0000.png: 480x640 1 person, 49.0ms\n",
      "Speed: 1.5ms preprocess, 49.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0001.png: 480x640 1 person, 41.7ms\n",
      "Speed: 0.9ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0002.png: 480x640 1 person, 1 suitcase, 47.5ms\n",
      "Speed: 1.3ms preprocess, 47.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0003.png: 480x640 1 person, 50.8ms\n",
      "Speed: 1.1ms preprocess, 50.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0004.png: 480x640 1 person, 43.3ms\n",
      "Speed: 0.9ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0005.png: 480x640 1 person, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0006.png: 480x640 1 person, 1 suitcase, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0007.png: 480x640 1 person, 40.7ms\n",
      "Speed: 0.9ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0008.png: 480x640 1 person, 1 suitcase, 41.7ms\n",
      "Speed: 0.9ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/giannos/Downloads/PPHAUall/PPHAU/homework2.1/data/rgb/frame_0009.png: 480x640 1 person, 41.0ms\n",
      "Speed: 0.9ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Segmentation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_SAMPLES):\n",
    "    rgb_path = os.path.join(EXTRACTED_RGB, f\"frame_{i:04d}.png\")\n",
    "    depth_path = os.path.join(EXTRACTED_DEPTH, f\"frame_{i:04d}.png\")\n",
    "    if not os.path.exists(rgb_path) or not os.path.exists(depth_path):\n",
    "        print(f\"Skipping frame {i}: file missing\")\n",
    "        continue\n",
    "\n",
    "    rgb = cv2.imread(rgb_path)\n",
    "    depth = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n",
    "    xyz = depth_to_xyz(depth, fx, fy, cx, cy)\n",
    "\n",
    "    results = model(rgb_path) \n",
    "\n",
    "    segmentation_mask = np.zeros(rgb.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(rgb.shape[1], x2), min(rgb.shape[0], y2)\n",
    "        roi_rgb = rgb[y1:y2, x1:x2]\n",
    "        roi_xyz = xyz[y1:y2, x1:x2]\n",
    "        if roi_rgb.size == 0:\n",
    "            continue\n",
    "        mask = clean_and_cluster(roi_rgb, roi_xyz)\n",
    "        segmentation_mask[y1:y2, x1:x2] = mask\n",
    "\n",
    "    cv2.imwrite(os.path.join(OVERLAY_OUT, f\"mask_{i:04d}.png\"), segmentation_mask * 255)\n",
    "    overlay = overlay_function(rgb, segmentation_mask)\n",
    "    cv2.imwrite(os.path.join(OVERLAY_OUT, f\"segmented_{i:04d}.png\"), overlay)\n",
    "\n",
    "print(\"Segmentation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b8d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
